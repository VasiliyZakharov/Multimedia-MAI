{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "5149eb08-a4cf-4e72-94bc-760c8a021144",
      "cell_type": "markdown",
      "source": "# Лабораторная работа №2: Проведение исследований с логистической и линейной регрессией",
      "metadata": {}
    },
    {
      "id": "cb6e13e2-6aef-4835-acbe-7cf80651f856",
      "cell_type": "markdown",
      "source": "## Задача классификации",
      "metadata": {}
    },
    {
      "id": "665f44a0-3f3e-4af7-a034-149a80bf6320",
      "cell_type": "markdown",
      "source": "## 2. Создание бейзлайна и оценка качества",
      "metadata": {}
    },
    {
      "id": "90af0830-ca97-4280-a2f5-1c559f8f067e",
      "cell_type": "code",
      "source": "X = bl_cdata.drop('HeartDisease', axis=1) # Все столбцы кроме 'HeartDisease' - это признаки\ny = bl_cdata['HeartDisease'] # 'HeartDisease' - это целевая переменная, которую мы хотим предсказать\n\n# Разделяем данные на обучающую и тестовую выборки\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Масштабируем признаки, это важно для логистической регрессии\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train) # Масштабируем обучающие данные\nX_test_scaled = scaler.transform(X_test) # Масштабируем тестовые данные\n\n# Создаем модель логистической регрессии\nmodel = LogisticRegression(random_state=42, solver='liblinear') # solver='liblinear' для небольших наборов данных\n\n# Обучаем модель на масштабированных обучающих данных\nmodel.fit(X_train_scaled, y_train)\n\n# Делаем предсказания на масштабированных тестовых данных\ny_pred = model.predict(X_test_scaled)\n\n# Вычисляем метрики\naccuracy = accuracy_score(y_test, y_pred) # Доля правильных ответов\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0) # Точность предсказаний для каждого класса, взвешенная\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0) # Полнота предсказаний для каждого класса, взвешенная\n\n# Выводим метрики\nprint(f\"Метрики для классификации (Логистическая регрессия):\")\nprint(f\"  Accuracy: {accuracy:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2323548f-151e-4396-b797-b5d11ba0c719",
      "cell_type": "code",
      "source": "Метрики для классификации (Логистическая регрессия):\n  Accuracy: 0.8533\n  Precision: 0.8572\n  Recall: 0.8533",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "517d38a8-86c1-48ef-882c-dfbf26484091",
      "cell_type": "markdown",
      "source": "Точность для встроенных моделей sklearn оказалась очень хорошей. Попробуем улучшить бейзлайн:",
      "metadata": {}
    },
    {
      "id": "083e401c-84ff-42f6-b51b-234f9e5e27f2",
      "cell_type": "markdown",
      "source": "## 3. Улучшение бейзлайна",
      "metadata": {}
    },
    {
      "id": "15ad9e5c-34de-45b2-a4c4-0dedb5b0eca9",
      "cell_type": "markdown",
      "source": "Гипотеза 1: Не все признаки одинаково важны для предсказания наличия сердечных заболеваний. Отбор наиболее значимых признаков с помощью статистических методов (например, ANOVA F-статистика) может улучшить производительность модели, уменьшив шум и переобучение.\nГипотеза 2: Логистическая регрессия может быть подвержена переобучению, особенно если есть много признаков. Использование регуляризации (L1 или L2) может помочь модели обобщаться лучше, предотвращая переобучение.",
      "metadata": {}
    },
    {
      "id": "c607f047-c1bb-444d-864e-3a5dbb185f34",
      "cell_type": "code",
      "source": "Отбор признаков",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "60d98c1f-0da5-4a1d-8593-f699b9cad557",
      "cell_type": "code",
      "source": "\ndef evaluate_model(model, X, y, cv=5):\n    scoring = {'accuracy': make_scorer(accuracy_score),\n                'precision': make_scorer(precision_score, average='weighted', zero_division=0),\n                'recall': make_scorer(recall_score, average='weighted', zero_division=0)}\n    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, error_score='raise')\n    return pd.DataFrame(scores).agg(['mean', 'std']).filter(regex='test_')\n\n\nbaseline_model = Pipeline([('scaler', StandardScaler()),\n                           ('model', LogisticRegression(random_state=42, solver='liblinear'))])\nbaseline_scores = evaluate_model(baseline_model, X,y)\nprint(\"Бейзлайн:\")\nprint(baseline_scores)\n\n\nbest_k = 0\nbest_score = 0\nfor k in range(1, X.shape[1] + 1):\n    feature_selector = Pipeline([('scaler', StandardScaler()),\n                                ('selector', SelectKBest(score_func=f_classif, k=k)),\n                                ('model', LogisticRegression(random_state=42, solver='liblinear'))])\n    scores = evaluate_model(feature_selector, X,y)\n    mean_accuracy = scores['test_accuracy']['mean']\n    if mean_accuracy > best_score:\n        best_score = mean_accuracy\n        best_k = k\nprint(f\"\\nЛучшее количество признаков: {best_k}, Accuracy: {best_score}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2279d05b-7cae-4e74-a494-ed3598d5b7b4",
      "cell_type": "code",
      "source": "Бейзлайн:\n      test_accuracy  test_precision  test_recall\nmean       0.8267        0.8386     0.8267",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8db92d57-1115-4ede-8e40-83ffabe3c875",
      "cell_type": "markdown",
      "source": "Регуляризация",
      "metadata": {}
    },
    {
      "id": "77f45691-2c05-4b1e-9e9f-f3115cff7809",
      "cell_type": "code",
      "source": "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n             'penalty': ['l1', 'l2']}\ngrid_search = GridSearchCV(LogisticRegression(random_state=42, solver='liblinear'),\n                        param_grid, cv=5, scoring='accuracy')\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\ngrid_search.fit(X_train_scaled, y_train)\n\nprint(f\"\\nЛучшие параметры регуляризации: {grid_search.best_params_}\")\nbest_reg_model = grid_search.best_estimator_\nscores = evaluate_model(Pipeline([('scaler', StandardScaler()),\n                                ('model', best_reg_model)]), X,y)\nprint(\"Метрики для лучшей модели с регуляризацией:\")\nprint(scores)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "53690a87-6a60-4d08-a403-be32b64a1369",
      "cell_type": "code",
      "source": "      test_accuracy  test_precision  test_recall\nmean       0.8278        0.8394       0.8278",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "59069a6a-b925-4800-aa2b-14bbea225e75",
      "cell_type": "code",
      "source": "Предсказание на тестовой выборке и оценка качества",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b2e35ee5-e767-46b7-a89c-417c8b248d9f",
      "cell_type": "code",
      "source": "print(\"\\nУлучшенный бейзлайн \")\nimproved_baseline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('selector', SelectKBest(score_func=f_classif, k=best_k)),\n    ('model', LogisticRegression(random_state=42, solver='liblinear', **grid_search.best_params_))\n])\n\nimproved_scores = evaluate_model(improved_baseline, X, y)\n\n\nimproved_baseline.fit(X, y)\n\nX_test_scaled = scaler.transform(X_test)\ny_pred = improved_baseline.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n\nprint(f\"Метрики для улучшенной модели (Логистическая регрессия):\")\nprint(f\"  Accuracy: {accuracy:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "48297b15-7e18-4ef9-80eb-5e0dd2121f51",
      "cell_type": "code",
      "source": "Метрики для улучшенной модели (Логистическая регрессия):\n  Accuracy: 0.8696\n  Precision: 0.8726\n  Recall: 0.8696",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b8e0b1fa-00a2-4ff8-81cb-1267f18257b2",
      "cell_type": "markdown",
      "source": "С помощью отбора признаков и регуляризации получилось незначительно улучшить результаты.",
      "metadata": {}
    },
    {
      "id": "595ad03f-ccfd-4b52-aeb9-0d2201eba042",
      "cell_type": "markdown",
      "source": "## 4. Имплементация алгоритма машинного обучения",
      "metadata": {}
    },
    {
      "id": "17a43cf6-def2-4cb0-a554-e1553f03c055",
      "cell_type": "markdown",
      "source": "Напишем собственную реализацию логистической регрессии:",
      "metadata": {}
    },
    {
      "id": "2acc13fb-cc54-4d3d-ba35-823d577e076b",
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport pandas as pd\nclass LogisticRegressionCustom:\n    def __init__(self, learning_rate=0.01, n_iterations=1000, regularization=None, lambda_reg=0.1):\n        self.learning_rate = learning_rate\n        self.n_iterations = n_iterations\n        self.weights = None\n        self.bias = None\n        self.regularization = regularization\n        self.lambda_reg = lambda_reg\n\n    def _sigmoid(self, z):\n        return 1 / (1 + np.exp(-z))\n    def _cost_function(self, y, y_predicted):\n        m = len(y)\n        cost = -1/m * np.sum(y * np.log(y_predicted) + (1 - y) * np.log(1 - y_predicted))\n        if self.regularization == 'l1':\n                cost += (self.lambda_reg / (2 * m)) * np.sum(np.abs(self.weights))\n        elif self.regularization == 'l2':\n            cost += (self.lambda_reg / (2 * m)) * np.sum(self.weights**2)\n        return cost\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n        costs = []\n        for _ in range(self.n_iterations):\n            linear_model = np.dot(X, self.weights) + self.bias\n            y_predicted = self._sigmoid(linear_model)\n            cost = self._cost_function(y,y_predicted)\n            costs.append(cost)\n            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n            db = (1 / n_samples) * np.sum(y_predicted - y)\n            if self.regularization == 'l1':\n                dw += (self.lambda_reg / n_samples) * np.sign(self.weights)\n            elif self.regularization == 'l2':\n                dw += (self.lambda_reg / n_samples) * self.weights\n\n            self.weights -= self.learning_rate * dw\n            self.bias -= self.learning_rate * db\n\n    def predict(self, X):\n        linear_model = np.dot(X, self.weights) + self.bias\n        y_predicted = self._sigmoid(linear_model)\n        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n        return np.array(y_predicted_cls)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ba4fcddb-c2b3-49c3-8352-d31885aec14e",
      "cell_type": "markdown",
      "source": "Обучаем имплементированные модели и оцением их качество",
      "metadata": {}
    },
    {
      "id": "03c71a79-1684-42ec-81aa-c0ced1627831",
      "cell_type": "code",
      "source": "X = bl_cdata.drop('HeartDisease', axis=1).values\ny = bl_cdata['HeartDisease'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nmodel = LogisticRegressionCustom(learning_rate=0.01, n_iterations=1000)\nmodel.fit(X_train_scaled, y_train)\n\ny_pred = model.predict(X_test_scaled)\n\n\ndef evaluate_model(y_true, y_pred, model_name):\n  accuracy = accuracy_score(y_true, y_pred)\n  precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n  recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n  print(f\"Метрики для модели:\")\n  print(f\"  Accuracy: {accuracy:.4f}\")\n  print(f\"  Precision: {precision:.4f}\")\n  print(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3622c6a7-f30e-4a30-bfc2-41d21c23939c",
      "cell_type": "code",
      "source": "Метрики для модели:\n  Accuracy: 0.8587\n  Precision: 0.8634\n  Recall: 0.8587",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6f254fc3-6191-412b-a5cb-ce1eabe87906",
      "cell_type": "markdown",
      "source": "Результат даже лучше, чем у неулучшенной библиотечной модели. Теперь добавим техники из улучшенного бейзлайна",
      "metadata": {}
    },
    {
      "id": "623e5d4d-3c8a-4534-96a6-60ffc077dce2",
      "cell_type": "code",
      "source": "\nfeature_selector = SelectKBest(score_func=f_classif, k=best_k)\nX_train_selected = feature_selector.fit_transform(X_train_scaled, y_train)\nX_test_selected = feature_selector.transform(X_test_scaled)\n\n\nmodel_l1 = LogisticRegressionCustom(learning_rate=0.01, n_iterations=1000, regularization='l1', lambda_reg=0.1)\nmodel_l1.fit(X_train_selected, y_train)\n\ny_pred_l1 = model_l1.predict(X_test_selected)\n\n# Вычисление метрик\ndef evaluate_model(y_true, y_pred, model_name):\n  accuracy = accuracy_score(y_true, y_pred)\n  precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n  recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n  print(f\"Метрики для модели:\")\n  print(f\"  Accuracy: {accuracy:.4f}\")\n  print(f\"  Precision: {precision:.4f}\")\n  print(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d2df477f-5d7b-4f1c-a86f-74251334eefe",
      "cell_type": "code",
      "source": "  Accuracy: 0.8641\n  Precision: 0.8680\n  Recall: 0.8641",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "20952379-60d1-4858-84fc-b3822e0d0d4a",
      "cell_type": "markdown",
      "source": "Результат близкий, но он немного слабее, чем у библиотечной версии.",
      "metadata": {}
    },
    {
      "id": "aa48a5c1-bf20-4822-87a2-4761ad4983f6",
      "cell_type": "markdown",
      "source": "## Задача регрессии",
      "metadata": {}
    },
    {
      "id": "6614bcb4-d647-4cda-a219-73de0aaeb9e0",
      "cell_type": "markdown",
      "source": "Линейная регрессия:",
      "metadata": {}
    },
    {
      "id": "ae48897b-56ca-496b-a7b4-e614b2822a21",
      "cell_type": "code",
      "source": "X = bl_rdata.drop(target_variable, axis=1)\ny = bl_rdata[target_variable]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nmodel_lr = LinearRegression()\nmodel_lr.fit(X_train_scaled, y_train)\n\ny_pred_lr = model_lr.predict(X_test_scaled)\n\n\nmae_lr = mean_absolute_error(y_test, y_pred_lr)\nr2_lr = r2_score(y_test, y_pred_lr)\n\nprint(f\"\\nМетрики для регрессии (Linear Regression):\")\nprint(f\"  MAE: {mae_lr:.4f}\")\nprint(f\"  R-squared: {r2_lr:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a1521126-ea06-46a4-9822-008714d949e5",
      "cell_type": "code",
      "source": "Метрики для регрессии (Linear Regression):\n  MAE: 0.2321\n  R-squared: 0.6865",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d78644f9-bde8-4b46-aa34-29d6f7dbfe0d",
      "cell_type": "markdown",
      "source": "Результат давольно средний. Попробуем улучшить бейзлайн",
      "metadata": {}
    },
    {
      "id": "afe8443e-9809-4ba6-947a-2706a4718945",
      "cell_type": "markdown",
      "source": "## 3. Улучшение бейзлайна",
      "metadata": {}
    },
    {
      "id": "9d9b7da5-f820-44f9-a2c9-128b2e89bd69",
      "cell_type": "markdown",
      "source": "Гипотезы: Признаки после One-Hot кодирования могут привносить шум, особенно если они не очень коррелируют с целевой переменной. Отбор наиболее релевантных признаков может помочь улучшить качество модели. Будем использовать SelectKBest с f_regression для выбора k лучших признаков и сравним результаты. Сформируем улучшенный бейзлайн по результатам проверки гипотез, а также обучим модели с улучшенным бейзлайном.",
      "metadata": {}
    },
    {
      "id": "b8804286-e67d-4bae-8827-3835b700ad9c",
      "cell_type": "code",
      "source": "selector = SelectKBest(score_func=f_regression, k=8)\nX_train_selected = selector.fit_transform(X_train_scaled, y_train)\nX_test_selected = selector.transform(X_test_scaled)\n\nmodel_lr_selected = LinearRegression()\nmodel_lr_selected.fit(X_train_selected, y_train)\ny_pred_lr_selected = model_lr_selected.predict(X_test_selected)\n\nmae_lr_selected = mean_absolute_error(y_test, y_pred_lr_selected)\nr2_lr_selected = r2_score(y_test, y_pred_lr_selected)\n\nprint(f\"\\nМетрики для регрессии (Linear Regression) с отбором признаков:\")\nprint(f\"  MAE: {mae_lr_selected:.4f}\")\nprint(f\"  R-squared: {r2_lr_selected:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "aa7d3f1c-ce6c-4eea-9f1f-a14c6718f6fa",
      "cell_type": "code",
      "source": "Метрики для регрессии (Linear Regression) с отбором признаков:\n  MAE: 0.2221\n  R-squared: 0.7079",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4e6c8851-3444-40ad-82c9-616672dbeb82",
      "cell_type": "markdown",
      "source": "Результат удалось незначительно улучшить.",
      "metadata": {}
    },
    {
      "id": "5682c056-aeff-43f8-9317-4c311e7e580b",
      "cell_type": "markdown",
      "source": "## 4. Имплементация алгоритма машинного обучения",
      "metadata": {}
    },
    {
      "id": "5badf112-7fa8-4f53-bfbd-69bc0b6c479c",
      "cell_type": "markdown",
      "source": "Модифицируем реализацию линейной регрессии:",
      "metadata": {}
    },
    {
      "id": "6cfd91d0-3385-467e-bba1-5d70f64c6cfd",
      "cell_type": "code",
      "source": "class LinearRegressionCustom:\n    def __init__(self):\n        self.w = None\n        self.b = None\n\n    def fit(self, X, y, learning_rate=0.01, n_iterations=1000):\n        n_samples, n_features = X.shape\n        self.w = np.zeros(n_features)\n        self.b = 0\n\n        for _ in range(n_iterations):\n            y_predicted = self.predict(X)\n            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n            db = (1 / n_samples) * np.sum(y_predicted - y)\n\n            self.w = self.w - learning_rate * dw\n            self.b = self.b - learning_rate * db\n\n    def predict(self, X):\n        return np.dot(X, self.w) + self.b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "799a2bed-80c3-445e-b8d9-92d2ffb3345f",
      "cell_type": "markdown",
      "source": "Обучаем имплементированные модели и оцением их качество",
      "metadata": {}
    },
    {
      "id": "c886f36a-5701-47fa-bc53-ffb96814b723",
      "cell_type": "code",
      "source": "X = bl_rdata.drop(target_variable, axis=1)\ny = bl_rdata[target_variable]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nmodel_lr_custom = LinearRegressionCustom()\nmodel_lr_custom.fit(X_train_scaled, y_train, learning_rate = 0.001, n_iterations = 2000) \n\ny_pred_lr_custom = model_lr_custom.predict(X_test_scaled)\n\nmae_lr_custom = mean_absolute_error(y_test, y_pred_lr_custom)\nr2_lr_custom = r2_score(y_test, y_pred_lr_custom)\n\nprint(f\"\\nМетрики для регрессии (Linear Regression Custom):\")\nprint(f\"  MAE: {mae_lr_custom:.4f}\")\nprint(f\"  R-squared: {r2_lr_custom:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d829b874-432d-4d8b-9ae8-c8d909bad7e1",
      "cell_type": "code",
      "source": "MAE: 0.2502\nR-squared: 0.6594",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "eb983868-5d57-4115-b814-80124ce5a709",
      "cell_type": "markdown",
      "source": "Как видно имплементрованная линейная регрессия работает немного хуже. Добавим техники из улучшенного бейзлайна",
      "metadata": {}
    },
    {
      "id": "877feaee-484f-4904-8b41-ecffca9a0ce6",
      "cell_type": "code",
      "source": "selector = SelectKBest(score_func=f_regression, k=8)\nX_train_selected = selector.fit_transform(X_train_scaled, y_train)\nX_test_selected = selector.transform(X_test_scaled)\n\nmodel_lr_custom = LinearRegressionCustom()\nmodel_lr_custom.fit(X_train_selected, y_train, learning_rate = 0.001, n_iterations = 2000) # можно настроить\n\ny_pred_lr_custom = model_lr_custom.predict(X_test_selected)\n\nmae_lr_custom = mean_absolute_error(y_test, y_pred_lr_custom)\nr2_lr_custom = r2_score(y_test, y_pred_lr_custom)\n\nprint(f\"\\nМетрики для регрессии (Linear Regression Custom):\")\nprint(f\"  MAE: {mae_lr_custom:.4f}\")\nprint(f\"  R-squared: {r2_lr_custom:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6e5628a0-48f6-422f-848d-22a8fcaf232d",
      "cell_type": "code",
      "source": "  MAE: 0.2362\n  R-squared: 0.6854",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ea0d7a9f-0be4-462f-8b2a-d6dbdf561593",
      "cell_type": "markdown",
      "source": "Видно, что после улучшения бейзлайн всё ещё не выдаёт столь же хорошие результаты, что и улучшенная библиотечная реализация.",
      "metadata": {}
    }
  ]
}