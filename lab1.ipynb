{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "\n\n# Лабораторная работа №1: Проведение исследований с алгоритмом KNN\n\n",
      "metadata": {
        "id": "MomV69_s935j"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Задача классификации",
      "metadata": {
        "id": "xaEpcH5T-P_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 1. Выбор начальных условий",
      "metadata": {
        "id": "1XvD7BN0-Kta"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Для задачи классификации был выбран датасет Heart Failure Prediction Dataset. Основная практическая ценность этого данных заключается в создании прогностических моделей для улучшения диагностики и лечения сердечной недостаточности.",
      "metadata": {
        "id": "b-hpg_KO-aVA"
      }
    },
    {
      "cell_type": "code",
      "source": "from functools import partial\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.neighbors import KNeighborsClassifier\n\ncdata= pd.read_csv(\"heart.csv\")\n\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1000)\n\nprint(cdata.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease\n0   40   M           ATA        140          289          0     Normal    172              N      0.0       Up             0\n1   49   F           NAP        160          180          0     Normal    156              N      1.0     Flat             1\n2   37   M           ATA        130          283          0         ST     98              N      0.0       Up             0\n3   48   F           ASY        138          214          0     Normal    108              Y      1.5     Flat             1\n4   54   M           NAP        150          195          0     Normal    122              N      0.0       Up             0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "cdata.info()",
      "metadata": {
        "id": "O58mtVDoUpxE"
      },
      "outputs": [],
      "execution_count": 346
    },
    {
      "cell_type": "code",
      "source": "RangeIndex: 918 entries, 0 to 917\nData columns (total 12 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   Age             918 non-null    int64  \n 1   Sex             918 non-null    object \n 2   ChestPainType   918 non-null    object \n 3   RestingBP       918 non-null    int64  \n 4   Cholesterol     918 non-null    int64  \n 5   FastingBS       918 non-null    int64  \n 6   RestingECG      918 non-null    object \n 7   MaxHR           918 non-null    int64  \n 8   ExerciseAngina  918 non-null    object \n 9   Oldpeak         918 non-null    float64\n 10  ST_Slope        918 non-null    object \n 11  HeartDisease    918 non-null    int64  \ndtypes: float64(1), int64(6), object(5)\nmemory usage: 86.2+ KB",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "В датасете присутствуют категореальные признаки, представленные в виде строк. Чтобы он стал пригоден для обучения модели их нужно преобразовать в набор численных признаков. Для этого воспользуемся one-hot encoding.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "columns_to_encode = ['RestingECG', 'ChestPainType', 'Sex', 'ExerciseAngina', 'ST_Slope']\nencoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nencoded_features = encoder.fit_transform(cdata[columns_to_encode])\nencoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(columns_to_encode))\nbl_cdata = pd.concat([cdata.drop(columns_to_encode, axis=1).reset_index(drop=True), encoded_df], axis=1)\nprint(bl_cdata.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  ...  ExerciseAngina_N  ExerciseAngina_Y  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up\n0   40        140          289          0    172  ...               1.0               0.0            0.0            0.0          1.0\n1   49        160          180          0    156  ...               1.0               0.0            0.0            1.0          0.0\n2   37        130          283          0     98  ...               1.0               0.0            0.0            0.0          1.0\n3   48        138          214          0    108  ...               0.0               1.0            0.0            1.0          0.0\n4   54        150          195          0    122  ...               1.0               0.0            0.0            0.0          1.0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Выбор метрик качества",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Accuracy измеряет долю правильно классифицированных объектов от общего числа объектов. Она показывает, насколько часто модель выдает верные прогнозы. Это простая и интуитивно понятная метрика, которая дает общее представление о том, насколько хорошо работает модель.\n2. Precision измеряет долю истинно-положительных результатов среди всех объектов, которые модель отнесла к положительному классу. Она показывает, насколько можно доверять прогнозам модели, если она предсказала положительный класс.\n3. Recall измеряет долю истинно-положительных результатов среди всех объектов, которые на самом деле принадлежат к положительному классу. Она показывает, насколько хорошо модель находит все объекты, которые принадлежат к целевому классу.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Создание бейзлайна и оценка качества",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Разделение на признаки (X) и целевую переменную (y). Далее разделение на обучающую и тестовую выборки",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model = KNeighborsClassifier(n_neighbors=best_k)\nmodel.fit(X_train_scaled, y_train)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Поиск оптимального k для KNN. Далее создание и обучение модели",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "param_grid = {'n_neighbors': range(1, 21)}\nknn = KNeighborsClassifier()\ngrid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train_scaled, y_train)\n\nbest_k = grid_search.best_params_['n_neighbors']\nprint(f\"Optimal k for KNN: {best_k}\")\n\n\nmodel = KNeighborsClassifier(n_neighbors=best_k)\nmodel.fit(X_train_scaled, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Предсказание на тестовой выборке и оценка качества",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_pred = model.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n\nprint(f\"Метрики для классификации (KNN):\")\nprint(f\"  Accuracy: {accuracy:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Метрики для классификации (KNN):\n  Accuracy: 0.8641\n  Precision: 0.8664\n  Recall: 0.8641",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Точность для встроенных моделей sklearn оказалась очень хорошей. Попробуем улучшить бейзлайн:",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Улучшение бейзлайна",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Гипотеза: Добавление Полиномиальных Признаков может улучшить модель. Взаимодействия между признаками могут иметь важное значение для предсказания. Добавление полиномиальных признаков (например, квадратов и попарных произведений исходных признаков) может помочь модели уловить нелинейные зависимости.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import PolynomialFeatures\n\ndef train_and_evaluate(X_train, y_train, X_test, y_test, k):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n    return accuracy, precision, recall\n\n\naccuracy_base, precision_base, recall_base = train_and_evaluate(X_train_scaled, y_train, X_test_scaled, y_test, best_k)\nprint(f\"Метрики без полиномиальных признаков:\")\nprint(f\"  Accuracy: {accuracy_base:.4f}\")\nprint(f\"  Precision: {precision_base:.4f}\")\nprint(f\"  Recall: {recall_base:.4f}\")\n\nfor degree in range(2, 4): \n    poly = PolynomialFeatures(degree=degree, include_bias=False)\n    X_train_poly = poly.fit_transform(X_train_scaled)\n    X_test_poly = poly.transform(X_test_scaled)\n\n    accuracy_poly, precision_poly, recall_poly = train_and_evaluate(X_train_poly, y_train, X_test_poly, y_test, best_k)\n    print(f\"Метрики с полиномиальными признаками (степень {degree}):\")\n    print(f\"  Accuracy: {accuracy_poly:.4f}\")\n    print(f\"  Precision: {precision_poly:.4f}\")\n    print(f\"  Recall: {recall_poly:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Метрики с полиномиальными признаками (степень 2):\n  Accuracy: 0.8696\n  Precision: 0.8702\n  Recall: 0.8696",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Использование полиномиальных признаков степени 2 не сильно, но улучшило результаты. Помимо этого в коде используется поиск оптимального k для KNN с weights='uniform', что увеличивает эффективность модели. Также была провереная гипотеза, что отбор наиболее информативных признаков может уменьшить шум в данных, улучшить обобщающую способность модели и, возможно, уменьшить вычислительные затраты. Однако он не продемонстрировал никакой эффективности. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Имплементация алгоритма машинного обучения ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Напишем собственную реализацию алгоритма KNN:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class KNN:\n    def __init__(self, k=3):\n        self.k = k\n        self.X_train = None\n        self.y_train = None\n\n    def fit(self, X, y):\n        self.X_train = X\n        self.y_train = y\n\n    def _euclidean_distance(self, x1, x2):\n        return np.sqrt(np.sum((x1 - x2)**2))\n\n    def predict(self, X):\n        y_pred = [self._predict(x) for x in X]\n        return np.array(y_pred)\n\n    def _predict(self, x):\n        distances = [self._euclidean_distance(x, x_train) for x_train in self.X_train]\n        k_indices = np.argsort(distances)[:self.k]\n        k_nearest_labels = [self.y_train[i] for i in k_indices]\n        most_common = Counter(k_nearest_labels).most_common(1)\n        return most_common[0][0]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Обучаем имплементированные модели и оцением их качество",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = bl_cdata.drop(\"HeartDisease\", axis=1).values\ny = bl_cdata[\"HeartDisease\"].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\nknn_model = KNN(k=5) \nknn_model.fit(X_train_scaled, y_train)\n\n\ny_pred = knn_model.predict(X_test_scaled)\n\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n\nprint(f\"Метрики для KNN (имплементированный):\")\nprint(f\"  Accuracy: {accuracy:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Метрики для KNN (имплементированный):\n  Accuracy: 0.8641\n  Precision: 0.8653\n  Recall: 0.8641",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Как видно имплементрованный KNN работает почти так же хорошо. Добавим техники из улучшенного бейзлайна ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = bl_cdata.drop(\"HeartDisease\", axis=1)\ny = bl_cdata[\"HeartDisease\"]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_train_poly = poly.fit_transform(X_train_scaled)\nX_test_poly = poly.transform(X_test_scaled)\n\n\nbest_k = None\nbest_accuracy = 0\nfor k in range(1, 21):\n  knn_model = KNN(k=k)\n  knn_model.fit(X_train_poly, y_train.values)\n\n  y_pred = knn_model.predict(X_test_poly)\n  accuracy = accuracy_score(y_test, y_pred)\n\n  if accuracy > best_accuracy:\n      best_accuracy = accuracy\n      best_k = k\n\nprint(f\"Optimal k for KNN: {best_k}\")\n\nknn_model = KNN(k=best_k)\nknn_model.fit(X_train_poly, y_train.values)\ny_pred = knn_model.predict(X_test_poly)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n\nprint(f\"Метрики для KNN (имплементированный, с полиномиальными признаками 2 степени и оптимальным k):\")\nprint(f\"  Accuracy: {accuracy:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Метрики для KNN (имплементированный, с полиномиальными признаками 2 степени и оптимальным k):\n  Accuracy: 0.8696\n  Precision: 0.8699\n  Recall: 0.8696",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "После улучшения, бейзлайн теперь выдаёт результаты, которые практически не отличаются от результатов библиотечной реализации.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Задача регрессии",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Для этой задачи был выбран датасет Depression Student Dataset. Датасет учащихся с депрессией может быть очень полезным для исследований и разработки решений в области психического здоровья, образования и социального благополучия. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from functools import partial\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.neighbors import KNeighborsClassifier\n\nrdata = pd.read_csv(\"DepressionStudentDataset.csv\")\n\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1000)\n\nprint(rdata.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "   Gender  Age  Academic Pressure  Study Satisfaction     Sleep Duration Dietary Habits Have you ever had suicidal thoughts ?  Study Hours  Financial Stress Family History of Mental Illness Depression\n0    Male   28                2.0                 4.0          7-8 hours       Moderate                                   Yes            9                 2                              Yes         No\n1    Male   28                4.0                 5.0          5-6 hours        Healthy                                   Yes            7                 1                              Yes         No\n2    Male   25                1.0                 3.0          5-6 hours      Unhealthy                                   Yes           10                 4                               No        Yes\n3    Male   23                1.0                 4.0  More than 8 hours      Unhealthy                                   Yes            7                 2                              Yes         No\n4  Female   31                1.0                 5.0  More than 8 hours        Healthy                                   Yes            4                 2                              Yes         No",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "rdata.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "RangeIndex: 502 entries, 0 to 501\nData columns (total 11 columns):\n #   Column                                 Non-Null Count  Dtype  \n---  ------                                 --------------  -----  \n 0   Gender                                 502 non-null    object \n 1   Age                                    502 non-null    int64  \n 2   Academic Pressure                      502 non-null    float64\n 3   Study Satisfaction                     502 non-null    float64\n 4   Sleep Duration                         502 non-null    object \n 5   Dietary Habits                         502 non-null    object \n 6   Have you ever had suicidal thoughts ?  502 non-null    object \n 7   Study Hours                            502 non-null    int64  \n 8   Financial Stress                       502 non-null    int64  \n 9   Family History of Mental Illness       502 non-null    object \n 10  Depression                             502 non-null    object \ndtypes: float64(2), int64(3), object(6)\nmemory usage: 43.3+ KB",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "В датасете присутствуют категореальные признаки, представленные в виде строк. Чтобы он стал пригоден для обучения модели их нужно преобразовать в набор численных признаков. Для этого воспользуемся one-hot encoding.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "columns_to_encode = ['Gender', 'Sleep Duration', 'Dietary Habits', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness', 'Depression']\nencoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nencoded_features = encoder.fit_transform(rdata[columns_to_encode])\nencoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(columns_to_encode))\nbl_rdata = pd.concat([rdata.drop(columns_to_encode, axis=1).reset_index(drop=True), encoded_df], axis=1)\nbl_cdata = bl_rdata.drop(columns=['Depression_No'])\nprint(bl_rdata.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "   Age  Academic Pressure  Study Satisfaction  Study Hours  ...  Family History of Mental Illness_No  Family History of Mental Illness_Yes  Depression_Yes\n0   28                2.0                 4.0            9  ...                                  0.0                                   1.0             0.0\n1   28                4.0                 5.0            7  ...                                  0.0                                   1.0             0.0\n2   25                1.0                 3.0           10  ...                                  1.0                                   0.0             1.0\n3   23                1.0                 4.0            7  ...                                  0.0                                   1.0             0.0\n4   31                1.0                 5.0            4  ...                                  0.0                                   1.0             0.0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Выбор метрик качества",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Были выбранны метрики MAE и R-squared, потому что они хорошо дополняют друг друга при оценке качества модели регрессии: MAE даёт интуитивно понятную оценку точности прогнозов в исходных единицах измерения, а R-squared оценивает, насколько хорошо модель объясняет изменчивость данных. Использование обеих метрик позволяет получить более полное представление о работе регрессионной модели.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Создание бейзлайна и оценка качества",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Всё аналогично задаче классификации",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "target_variable = 'Depression_Yes'\nX = bl_rdata.drop(target_variable, axis=1)\ny = bl_rdata[target_variable]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nmodel = KNeighborsRegressor(n_neighbors=2)\nmodel.fit(X_train_scaled, y_train)\n\ny_pred = model.predict(X_test_scaled)\n\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Метрики для регрессии (KNN):\")\nprint(f\"  MAE: {mae:.4f}\")\nprint(f\"  R-squared: {r2:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Метрики для регрессии (KNN):\n  MAE: 0.1040\n  R-squared: 0.7916",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Встроенные модели показывают приемлемую точность. Попытаемся её улучшить.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Улучшение бейзлайна",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Гипотезы: Признаки после One-Hot кодирования могут привносить шум, особенно если они не очень коррелируют с целевой переменной. Отбор наиболее релевантных признаков может помочь улучшить качество модели. Будем использовать SelectKBest с f_regression для выбора k лучших признаков и сравним результаты. \nТакже используем GridSearchCV для поиска оптимального значения гиперпараметра n_neighbors.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# --- Проверка Гипотезы 1: Отбор признаков ---\n\nbest_k = 0\nbest_r2_k = -np.inf\n\nfor k in range(1, X_train_scaled.shape[1] + 1):\n\n    vt = VarianceThreshold()\n    vt.fit(X_train_scaled)\n\n    indices = np.argsort(vt.variances_)[::-1][:k]\n\n    X_train_selected = X_train_scaled[:, indices]\n    X_test_selected = X_test_scaled[:, indices]\n\n    model = KNeighborsRegressor(n_neighbors=2)\n    model.fit(X_train_selected, y_train)\n\n    y_pred = model.predict(X_test_selected)\n    mae = mean_absolute_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n\n    if r2 > best_r2_k:\n        best_r2_k = r2\n        best_k = k\n\n    print(f\"  k={k}: MAE: {mae:.4f}, R2: {r2:.4f}\")\n\nprint(f\"Лучшее значение k для feature selection: {best_k}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "  k=1: MAE: 0.5000, R2: -0.0025\n  k=2: MAE: 0.5149, R2: -0.2704\n  k=3: MAE: 0.4950, R2: -0.5483\n  k=4: MAE: 0.4950, R2: -0.3895\n  k=5: MAE: 0.5050, R2: -0.5285\n  k=6: MAE: 0.4802, R2: -0.4789\n  k=7: MAE: 0.4802, R2: -0.4789\n  k=8: MAE: 0.4653, R2: -0.3300\n  k=9: MAE: 0.4653, R2: -0.3300\n  k=10: MAE: 0.3564, R2: -0.0124\n  k=11: MAE: 0.3416, R2: 0.0174\n  k=12: MAE: 0.2921, R2: 0.1960\n  k=13: MAE: 0.3119, R2: 0.1365\n  k=14: MAE: 0.0545, R2: 0.8908\n  k=15: MAE: 0.0891, R2: 0.8015\n  k=16: MAE: 0.1089, R2: 0.7419\n  k=17: MAE: 0.1287, R2: 0.7022\n  k=18: MAE: 0.0891, R2: 0.8213\n  k=19: MAE: 0.1040, R2: 0.7916\nЛучшее значение k для feature selection (без целевой переменной): 14",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# --- Проверка Гипотезы 2: Оптимизация гиперпараметра n_neighbors ---\nprint(\"\\n--- Проверка Гипотезы 2: Оптимизация n_neighbors ---\")\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('knn', KNeighborsRegressor())\n])\nparam_grid = {'knn__n_neighbors': np.arange(1, 21)}\n\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_absolute_error')\ngrid_search.fit(X_train, y_train)\n\nbest_n_neighbors = grid_search.best_params_['knn__n_neighbors']\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"  Лучший n_neighbors: {best_n_neighbors}\")\nprint(f\"  MAE: {mae:.4f}\")\nprint(f\"  R-squared: {r2:.4f}\")\n\nprint(\"\\n--- Baseline Model with best parameters ---\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "  Лучший n_neighbors: 1\n  MAE: 0.0594\n  R-squared: 0.7618",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Сформируем улучшенный бейзлайн по результатам проверки гипотез, а также обучим модели с улучшенным бейзлайном",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "selector = SelectKBest(score_func=f_regression, k=best_k) # Используем best_k найденный VarianceThreshold\nX_train_selected = selector.fit_transform(X_train_scaled, y_train)\nX_test_selected = selector.transform(X_test_scaled)\nnew_model = KNeighborsRegressor(n_neighbors=best_n_neighbors)\nnew_model.fit(X_train_selected, y_train)\ny_pred = new_model.predict(X_test_selected)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"New Baseline with selected features (f_regression) and optimized n_neighbors: MAE: {mae:.4f}, R2: {r2:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "New Baseline with selected features and optimized n_neighbors: MAE: 0.0198, R2: 0.9206",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Видно, что использование SelectKBest с f_regression для выбора k лучших признаков совместно с оптимизацией гиперпараметра n_neighbors крайне сильно улучшают результаты.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Имплементация алгоритма машинного обучения",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Модифицируем реализацию алгоритма KNN для регрессии:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class KNN:\n    def __init__(self, k=3, task_type='classification'):\n        self.k = k\n        self.X_train = None\n        self.y_train = None\n        self.task_type = task_type\n\n    def fit(self, X, y):\n        self.X_train = X\n        self.y_train = y\n\n    def _euclidean_distance(self, x1, x2):\n        return np.sqrt(np.sum((x1 - x2)**2))\n\n    def predict(self, X):\n        y_pred = [self._predict(x) for x in X]\n        return np.array(y_pred)\n\n    def _predict(self, x):\n        distances = [self._euclidean_distance(x, x_train) for x_train in self.X_train]\n        k_indices = np.argsort(distances)[:self.k]\n        k_nearest_labels = [self.y_train[i] for i in k_indices]\n\n        if self.task_type == 'classification':\n           most_common = Counter(k_nearest_labels).most_common(1)\n           return most_common[0][0]\n        elif self.task_type == 'regression':\n             return np.mean(k_nearest_labels)\n        else:\n            raise ValueError(\"Неверный task_type, значение должно быть 'classification' или 'regression'\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Обучаем имплементированные модели и оцением их качество",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "target_variable = 'Depression_Yes'\nX_reg = bl_rdata.drop(target_variable, axis=1).values\ny_reg = bl_rdata[target_variable].values\n\n# Разделение на обучающую и тестовую выборки\nX_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n\n# Масштабирование\nscaler_reg = StandardScaler()\nX_reg_train_scaled = scaler_reg.fit_transform(X_reg_train)\nX_reg_test_scaled = scaler_reg.transform(X_reg_test)\n\n# Инициализация и обучение модели KNN для регрессии\nknn_reg_model = KNN(k=5, task_type='regression')\n\n\nknn_reg_model.fit(X_reg_train_scaled, y_reg_train)\n\n# Предсказание на тестовой выборке\ny_reg_pred = knn_reg_model.predict(X_reg_test_scaled)\n\n# Оценка качества\nmae_reg = mean_absolute_error(y_reg_test, y_reg_pred)\nr2_reg = r2_score(y_reg_test, y_reg_pred)\n\nprint(f\"Метрики для KNN (имплементированный, регрессия):\")\nprint(f\"  MAE: {mae_reg:.4f}\")\nprint(f\"  R-squared: {r2_reg:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Метрики для KNN (имплементированный, регрессия):\n  MAE: 0.1089\n  R-squared: 0.8428",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Как видно имплементрованный KNN работает даже немного лучше. Добавим техники из улучшенного бейзлайна",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "target_variable = 'Depression_Yes'\nX_reg = bl_rdata.drop(target_variable, axis=1).values\ny_reg = bl_rdata[target_variable].values\n\n# Разделение на обучающую и тестовую выборки\nX_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n\n# Масштабирование\nscaler_reg = StandardScaler()\nX_reg_train_scaled = scaler_reg.fit_transform(X_reg_train)\nX_reg_test_scaled = scaler_reg.transform(X_reg_test)\n\n\n# --- Отбор признаков (VarianceThreshold) ---\nbest_k = 0\nbest_r2_k = -np.inf\n\nfor k in range(1, X_train_scaled.shape[1] + 1):\n\n    vt = VarianceThreshold()\n    vt.fit(X_train_scaled)\n\n    indices = np.argsort(vt.variances_)[::-1][:k]\n\n    X_train_selected = X_train_scaled[:, indices]\n    X_test_selected = X_test_scaled[:, indices]\n\n    model = KNeighborsRegressor(n_neighbors=2)\n    model.fit(X_train_selected, y_train)\n\n    y_pred = model.predict(X_test_selected)\n    mae = mean_absolute_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n\n    if r2 > best_r2_k:\n        best_r2_k = r2\n        best_k = k\n\n    print(f\"  k={k}: MAE: {mae:.4f}, R2: {r2:.4f}\")\n\nprint(f\"Лучшее значение k для feature selection (без целевой переменной): {best_k}\")\n\n# --- Оптимизация k (гиперпараметра) для KNN (используем GridSearchCV из sklearn) ---\nprint(\"\\n--- Оптимизация k (гиперпараметра) для KNN (GridSearchCV) ---\")\nindices = np.argsort(vt.variances_)[::-1][:best_k]\nX_reg_train_selected = X_reg_train_scaled[:, indices]\nX_reg_test_selected = X_reg_test_scaled[:, indices]\n\npipeline = Pipeline([\n    ('knn', KNeighborsRegressor())\n])\nparam_grid = {'knn__n_neighbors': np.arange(1, 21)}\n\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_absolute_error')\ngrid_search.fit(X_reg_train_selected, y_reg_train)\n\nbest_k_knn = grid_search.best_params_['knn__n_neighbors']\nprint(f\"Лучшее k для KNN (GridSearchCV): {best_k_knn}\")\n\n\n\nprint(\"\\n--- Новый бейзлайн ---\")\n\ncustom_knn_model = KNN(k=best_k_knn, task_type='regression')\ncustom_knn_model.fit(X_reg_train_selected, y_reg_train)\n\ny_reg_pred = custom_knn_model.predict(X_reg_test_selected)\nmae_reg = mean_absolute_error(y_reg_test, y_reg_pred)\nr2_reg = r2_score(y_reg_test, y_reg_pred)\n\nprint(f\"New Baseline (Custom KNN) with selected features and optimized k: MAE: {mae_reg:.4f}, R2: {r2_reg:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "MAE: 0.0297, R2: 0.8809",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Видно, что после улучшения бейзлайн всё ещё не выдаёт столь же хорошие результаты, что и улучшенная библиотечная реализация.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}