{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Лабораторная работа №3: Проведение исследований с решающим деревом",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Задача классификации",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Создание бейзлайна и оценка качества",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = bl_cdata.drop('HeartDisease', axis=1) \ny = bl_cdata['HeartDisease'] \n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\nmodel = DecisionTreeClassifier(random_state=42)\n\n\nmodel.fit(X_train_scaled, y_train)\n\n\ny_pred = model.predict(X_test_scaled)\n\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n\n\nprint(f\"Метрики для классификации (Решающее дерево):\")\nprint(f\"  Accuracy: {accuracy:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "  Accuracy: 0.8043\n  Precision: 0.8114\n  Recall: 0.8043",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Точность для встроенных моделей sklearn оказалась очень хорошей. Попробуем улучшить бейзлайн:",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Улучшение бейзлайна",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Проведем улучшение бейзлайна на основе гипотезы о подборе гиперпараметров решающего дерева. Подбор оптимальных значений гиперпараметров max_depth, min_samples_split и min_samples_leaf для модели DecisionTreeClassifier позволит улучшить метрики классификации (Accuracy, Precision, Recall) по сравнению с моделью с параметрами по умолчанию.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = bl_cdata.drop('HeartDisease', axis=1)\ny = bl_cdata['HeartDisease']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\nparam_grid = {\n    'max_depth': [3, 5, 7, 10, None], \n    'min_samples_split': [2, 5, 10, 20],\n    'min_samples_leaf': [1, 2, 5, 10]\n}\n\n\nmodel = DecisionTreeClassifier(random_state=42)\n\n\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1) \n\n\ngrid_search.fit(X_train_scaled, y_train)\n\n\nprint(f\"Лучшие параметры: {grid_search.best_params_}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Лучшие параметры: {'max_depth': 7, 'min_samples_leaf': 10, 'min_samples_split': 2}",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Обучаем модели с лучшими параметрами",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "best_model = grid_search.best_estimator_\n\n# Делаем предсказания на масштабированных тестовых данных\ny_pred = best_model.predict(X_test_scaled)\n\n# Вычисляем метрики\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n\n# Выводим метрики\nprint(f\"Метрики для классификации (Решающее дерево с подбором параметров):\")\nprint(f\"  Accuracy: {accuracy:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "  Accuracy: 0.8696\n  Precision: 0.8712\n  Recall: 0.8696",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "С помощью отбора признаков и регуляризации получилось незначительно улучшить результаты.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Имплементация алгоритма машинного обучения",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Напишем собственную реализацию решающего дерева для классификации",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom collections import Counter\n\n\nclass Node:\n    \"\"\"Представляет узел дерева решений.\"\"\"\n\n    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n        self.feature = feature  # индекс признака, по которому разделяем\n        self.threshold = threshold  # порог разделения\n        self.left = left  # левый дочерний узел\n        self.right = right  # правый дочерний узел\n        self.value = value  # значение листа (если узел листовой)\n\n\nclass DecisionTree:\n    \"\"\"Реализация дерева решений для классификации.\"\"\"\n\n    def __init__(self, min_samples_split=2, max_depth=10):\n        self.min_samples_split = min_samples_split\n        self.max_depth = max_depth\n        self.root = None\n\n    def _gini(self, y):\n        \"\"\"Вычисляет индекс Джини.\"\"\"\n        if len(y) == 0:\n            return 0\n        counts = Counter(y)\n        impurity = 1\n        for label in counts:\n            p = counts[label] / len(y)\n            impurity -= p ** 2\n        return impurity\n\n    def _information_gain(self, y, left_y, right_y):\n        \"\"\"Вычисляет прирост информации.\"\"\"\n        p = len(left_y) / len(y)\n        gain = self._gini(y) - p * self._gini(left_y) - (1 - p) * self._gini(right_y)\n        return gain\n\n    def _best_split(self, X, y):\n        \"\"\"Находит наилучшее разбиение для набора данных.\"\"\"\n        best_gain = 0\n        best_feature = None\n        best_threshold = None\n\n        for feature in range(X.shape[1]):\n            thresholds = np.unique(X[:, feature])\n            for threshold in thresholds:\n                left_indices = X[:, feature] <= threshold\n                right_indices = X[:, feature] > threshold\n                left_y = y[left_indices]\n                right_y = y[right_indices]\n\n                if len(left_y) < 1 or len(right_y) < 1:\n                    continue\n                gain = self._information_gain(y, left_y, right_y)\n                if gain > best_gain:\n                    best_gain = gain\n                    best_feature = feature\n                    best_threshold = threshold\n        return best_feature, best_threshold\n\n    def _build_tree(self, X, y, depth=0):\n        \"\"\"Рекурсивно строит дерево решений.\"\"\"\n\n        if len(y) < self.min_samples_split or depth == self.max_depth or self._gini(y) == 0:\n            counts = Counter(y)\n            value = max(counts, key=counts.get)\n            return Node(value=value)\n\n        feature, threshold = self._best_split(X, y)\n        if feature is None:\n            counts = Counter(y)\n            value = max(counts, key=counts.get)\n            return Node(value=value)\n\n        left_indices = X[:, feature] <= threshold\n        right_indices = X[:, feature] > threshold\n        left_X = X[left_indices]\n        right_X = X[right_indices]\n        left_y = y[left_indices]\n        right_y = y[right_indices]\n\n        left_subtree = self._build_tree(left_X, left_y, depth + 1)\n        right_subtree = self._build_tree(right_X, right_y, depth + 1)\n        return Node(feature, threshold, left_subtree, right_subtree)\n\n    def fit(self, X, y):\n        \"\"\"Обучает дерево решений.\"\"\"\n        self.root = self._build_tree(X, y)\n\n    def _predict_sample(self, x, node):\n        \"\"\"Предсказывает метку класса для одного образца.\"\"\"\n        if node.value is not None:\n            return node.value\n        if x[node.feature] <= node.threshold:\n            return self._predict_sample(x, node.left)\n        else:\n            return self._predict_sample(x, node.right)\n\n    def predict(self, X):\n        \"\"\"Предсказывает метки классов для набора образцов.\"\"\"\n        predictions = []\n        for x in X:\n            predictions.append(self._predict_sample(x, self.root))\n        return np.array(predictions)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Обучим модели и оценим их качество",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = bl_cdata.drop('HeartDisease', axis=1)\ny = bl_cdata['HeartDisease'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\nmodel = DecisionTree(max_depth=5)  \nmodel.fit(X_train_scaled, y_train)\n\n\ny_pred = model.predict(X_test_scaled)\n\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n\nprint(\"Метрики для нашей модели дерева решений:\")\nprint(f\"  Accuracy: {accuracy:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "  Accuracy: 0.8750\n  Precision: 0.8772\n  Recall: 0.8750",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Точность реализованных вручную моделей в даже лучше библиотечных.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Задача регрессии",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Создание бейзлайна и оценка качества",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = bl_rdata.drop(target_variable, axis=1)\ny = bl_rdata[target_variable]\n\n# Разделяем данные на обучающую и тестовую выборки\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Масштабируем признаки (стандартизация)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Создаем модель решающего дерева для регрессии\nmodel = DecisionTreeRegressor(random_state=42)\n\n# Обучаем модель на масштабированных обучающих данных\nmodel.fit(X_train_scaled, y_train)\n\n# Делаем предсказания на масштабированных тестовых данных\ny_pred = model.predict(X_test_scaled)\n\n# Вычисляем метрики для регрессии\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Выводим метрики\nprint(f\"Метрики для регрессии (Решающее дерево):\")\nprint(f\"  Mean Absolute Error: {mae:.4f}\")\nprint(f\"  R-squared: {r2:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "  Mean Absolute Error: 0.0990\n  R-squared: 0.6030",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Точность для встроенной в Sklearn модели решающего дерева получилась приемлемой. Попробуем её улучшить",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Улучшение бейзлайна",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Воспользуемся тем же методом, что и в случае с классификацией",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = bl_rdata.drop(target_variable, axis=1)\ny = bl_rdata[target_variable]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nparam_grid = {\n    'max_depth': [3, 5, 7, 10, None],\n    'min_samples_split': [2, 5, 10, 20],\n    'min_samples_leaf': [1, 2, 5, 10]\n}\n\n\nmodel = DecisionTreeRegressor(random_state=42)\n\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error', verbose=2, n_jobs=-1)\n\ngrid_search.fit(X_train_scaled, y_train)\n\nprint(f\"Лучшие параметры: {grid_search.best_params_}\")\n\nbest_model = grid_search.best_estimator_\n\ny_pred = best_model.predict(X_test_scaled)\n\n\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Метрики для регрессии (Решающее дерево с подбором параметров):\")\nprint(f\"  Mean Absolute Error: {mae:.4f}\")\nprint(f\"  R-squared: {r2:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "  Mean Absolute Error: 0.0672\n  R-squared: 0.6520",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Изменения незначительные",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Имплементация алгоритма машинного обучения",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Напишем собственную реализацию решающего дерева для регрессии",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n\n# Кастомная реализация DecisionTreeRegressor\nclass Node:\n    \"\"\"Представляет узел дерева решений.\"\"\"\n\n    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n        self.feature = feature  # индекс признака, по которому разделяем\n        self.threshold = threshold  # порог разделения\n        self.left = left  # левый дочерний узел\n        self.right = right  # правый дочерний узел\n        self.value = value  # значение листа (если узел листовой)\n\n\nclass DecisionTreeRegressor:\n    \"\"\"Реализация дерева решений для регрессии.\"\"\"\n\n    def __init__(self, min_samples_split=2, max_depth=10):\n        self.min_samples_split = min_samples_split\n        self.max_depth = max_depth\n        self.root = None\n\n    def _variance(self, y):\n        \"\"\"Вычисляет дисперсию.\"\"\"\n        if len(y) == 0:\n            return 0\n        return np.var(y)\n\n    def _mean_squared_error(self, y):\n        \"\"\"Вычисляет среднеквадратичную ошибку\"\"\"\n        if len(y) == 0:\n            return 0\n        mean = np.mean(y)\n        return np.mean((y - mean) ** 2)\n\n    def _information_gain(self, y, left_y, right_y):\n        \"\"\"Вычисляет прирост информации, используя дисперсию.\"\"\"\n        p = len(left_y) / len(y)\n        # gain = self._variance(y) - p * self._variance(left_y) - (1 - p) * self._variance(right_y)\n        gain = self._mean_squared_error(y) - p * self._mean_squared_error(left_y) - (1 - p) * self._mean_squared_error(\n            right_y)\n        return gain\n\n    def _best_split(self, X, y):\n        \"\"\"Находит наилучшее разбиение для набора данных.\"\"\"\n        best_gain = 0\n        best_feature = None\n        best_threshold = None\n\n        for feature in range(X.shape[1]):\n            thresholds = np.unique(X[:, feature])\n            for threshold in thresholds:\n                left_indices = X[:, feature] <= threshold\n                right_indices = X[:, feature] > threshold\n                left_y = y[left_indices]\n                right_y = y[right_indices]\n\n                if len(left_y) < 1 or len(right_y) < 1:\n                    continue\n                gain = self._information_gain(y, left_y, right_y)\n                if gain > best_gain:\n                    best_gain = gain\n                    best_feature = feature\n                    best_threshold = threshold\n        return best_feature, best_threshold\n\n    def _build_tree(self, X, y, depth=0):\n        \"\"\"Рекурсивно строит дерево решений.\"\"\"\n\n        if len(y) < self.min_samples_split or depth == self.max_depth or self._mean_squared_error(y) == 0:\n            value = np.mean(y)\n            return Node(value=value)\n\n        feature, threshold = self._best_split(X, y)\n        if feature is None:\n            value = np.mean(y)\n            return Node(value=value)\n\n        left_indices = X[:, feature] <= threshold\n        right_indices = X[:, feature] > threshold\n        left_X = X[left_indices]\n        right_X = X[right_indices]\n        left_y = y[left_indices]\n        right_y = y[right_indices]\n\n        left_subtree = self._build_tree(left_X, left_y, depth + 1)\n        right_subtree = self._build_tree(right_X, right_y, depth + 1)\n        return Node(feature, threshold, left_subtree, right_subtree)\n\n    def fit(self, X, y):\n        \"\"\"Обучает дерево решений.\"\"\"\n        self.root = self._build_tree(X, y)\n\n    def _predict_sample(self, x, node):\n        \"\"\"Предсказывает значение для одного образца.\"\"\"\n        if node.value is not None:\n            return node.value\n        if x[node.feature] <= node.threshold:\n            return self._predict_sample(x, node.left)\n        else:\n            return self._predict_sample(x, node.right)\n\n    def predict(self, X):\n        \"\"\"Предсказывает значения для набора образцов.\"\"\"\n        predictions = []\n        for x in X:\n            predictions.append(self._predict_sample(x, self.root))\n        return np.array(predictions)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Обучаем имплементированные модели и оцением их качество\n     ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\nX = bl_rdata.drop(target_variable, axis=1)\ny = bl_rdata[target_variable]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\nmodel = DecisionTreeRegressor(min_samples_split=5, max_depth=5)\nmodel.fit(X_train_scaled, y_train)\n\n\ny_pred = model.predict(X_test_scaled)\n\n\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Метрики для регрессии (Решающее дерево - Кастомная реализация):\")\nprint(f\"  Mean Absolute Error: {mae:.4f}\")\nprint(f\"  R-squared: {r2:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "  Mean Absolute Error: 0.1592\n  R-squared: 0.6377",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Метрики не очень сильно отличаются от пункта 2",
      "metadata": {}
    }
  ]
}